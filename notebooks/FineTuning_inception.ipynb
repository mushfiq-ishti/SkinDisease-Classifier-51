{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Importing Libraries</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-29T10:21:01.624562Z",
     "iopub.status.busy": "2025-08-29T10:21:01.624359Z",
     "iopub.status.idle": "2025-08-29T10:21:45.011745Z",
     "shell.execute_reply": "2025-08-29T10:21:45.010881Z",
     "shell.execute_reply.started": "2025-08-29T10:21:01.624543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:21:45.012956Z",
     "iopub.status.busy": "2025-08-29T10:21:45.012708Z",
     "iopub.status.idle": "2025-08-29T10:22:05.944555Z",
     "shell.execute_reply": "2025-08-29T10:22:05.943680Z",
     "shell.execute_reply.started": "2025-08-29T10:21:45.012937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "#from imblearn.metrics import geometric_mean_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Dataset Loading</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:05.947098Z",
     "iopub.status.busy": "2025-08-29T10:22:05.946684Z",
     "iopub.status.idle": "2025-08-29T10:22:13.358345Z",
     "shell.execute_reply": "2025-08-29T10:22:13.357581Z",
     "shell.execute_reply.started": "2025-08-29T10:22:05.947081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/input/50-skin-disease/Best_50_class' \n",
    "dataset = datasets.ImageFolder(root= dataset_path)\n",
    "class_names = dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:13.359464Z",
     "iopub.status.busy": "2025-08-29T10:22:13.359205Z",
     "iopub.status.idle": "2025-08-29T10:22:13.366173Z",
     "shell.execute_reply": "2025-08-29T10:22:13.365349Z",
     "shell.execute_reply.started": "2025-08-29T10:22:13.359443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset.targets has numeric labels for each image\n",
    "counts = Counter(dataset.targets)\n",
    "\n",
    "# Map counts to class names\n",
    "for class_idx, count in counts.items():\n",
    "    print(f\"{dataset.classes[class_idx]}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:13.367692Z",
     "iopub.status.busy": "2025-08-29T10:22:13.367108Z",
     "iopub.status.idle": "2025-08-29T10:22:13.385772Z",
     "shell.execute_reply": "2025-08-29T10:22:13.385073Z",
     "shell.execute_reply.started": "2025-08-29T10:22:13.367672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_counts = pd.DataFrame({\n",
    "    \"Class\": [dataset.classes[idx] for idx in counts.keys()],\n",
    "    \"Count\": [counts[idx] for idx in counts.keys()]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_counts.to_csv(\"class_counts.csv\", index=False)\n",
    "\n",
    "print(\"Counts saved to class_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Inception-with Unfrozen Layers</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Dataset Splitting</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:13.386799Z",
     "iopub.status.busy": "2025-08-29T10:22:13.386462Z",
     "iopub.status.idle": "2025-08-29T10:22:18.415936Z",
     "shell.execute_reply": "2025-08-29T10:22:18.415266Z",
     "shell.execute_reply.started": "2025-08-29T10:22:13.386775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "# =========================\n",
    "# Dataset creation\n",
    "# =========================\n",
    "data_dir = dataset_path  # your dataset folder\n",
    "img_size = (299, 299)    # InceptionV3 expects 299x299\n",
    "batch_size = 32\n",
    "\n",
    "# =========================\n",
    "# Step 1: 70% training set\n",
    "# =========================\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,   # leave 30% for val+test\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 2: 30% val+test pool\n",
    "# =========================\n",
    "val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 3: Split val_test_ds into 15% val + 15% test\n",
    "# =========================\n",
    "val_test_size = val_test_ds.cardinality().numpy()\n",
    "val_size = val_test_size // 2\n",
    "test_size = val_test_size - val_size  # handles odd numbers safely\n",
    "\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "# =========================\n",
    "# Preprocessing function\n",
    "# =========================\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess_batch(images, labels):\n",
    "    images = preprocess_input(images)  # Apply InceptionV3 preprocessing\n",
    "    return images, labels\n",
    "\n",
    "train_ds = train_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:18.416935Z",
     "iopub.status.busy": "2025-08-29T10:22:18.416737Z",
     "iopub.status.idle": "2025-08-29T10:22:18.423154Z",
     "shell.execute_reply": "2025-08-29T10:22:18.422404Z",
     "shell.execute_reply.started": "2025-08-29T10:22:18.416918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32  # Use the same batch size you set\n",
    "\n",
    "def dataset_size(dataset):\n",
    "    # Get number of batches\n",
    "    batches = dataset.cardinality().numpy()\n",
    "    if batches == tf.data.INFINITE_CARDINALITY or batches == tf.data.UNKNOWN_CARDINALITY:\n",
    "        return \"Unknown size\"\n",
    "    else:\n",
    "        return batches * batch_size\n",
    "\n",
    "print(\"Train set size:\", dataset_size(train_ds))\n",
    "print(\"Validation set size:\", dataset_size(val_ds))\n",
    "print(\"Test set size:\", dataset_size(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Compiling</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:18.424684Z",
     "iopub.status.busy": "2025-08-29T10:22:18.424014Z",
     "iopub.status.idle": "2025-08-29T10:22:21.926071Z",
     "shell.execute_reply": "2025-08-29T10:22:21.925247Z",
     "shell.execute_reply.started": "2025-08-29T10:22:18.424651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "num_classes = train_ds.element_spec[1].shape[-1]\n",
    "\n",
    "# 1) Base model\n",
    "base = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(299, 299, 3))\n",
    "base.trainable = False\n",
    "\n",
    "# 2) Classification head\n",
    "inputs = layers.Input(shape=(299, 299, 3))\n",
    "x = inputs\n",
    "x = preprocess_input(x)  # if you didn’t map in the dataset pipeline\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Training</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:22:21.928144Z",
     "iopub.status.busy": "2025-08-29T10:22:21.927847Z",
     "iopub.status.idle": "2025-08-29T10:24:22.043170Z",
     "shell.execute_reply": "2025-08-29T10:24:22.042420Z",
     "shell.execute_reply.started": "2025-08-29T10:22:21.928125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3) Warmup: train head only\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "warmup_cb = [\n",
    "    callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "    callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=\"val_loss\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:42:32.231987Z",
     "iopub.status.busy": "2025-08-29T10:42:32.231289Z",
     "iopub.status.idle": "2025-08-29T10:45:23.628970Z",
     "shell.execute_reply": "2025-08-29T10:45:23.628255Z",
     "shell.execute_reply.started": "2025-08-29T10:42:32.231960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Directory + filename to save best model\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"best_inception_model.h5\",   # <-- file will be saved here\n",
    "    save_best_only=True,         # save only the best model (lowest val_loss)\n",
    "    monitor=\"val_loss\",          # metric to monitor\n",
    "    mode=\"min\",                  # \"min\" because we want the lowest val_loss\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Warmup training ---\n",
    "history_1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "        ReduceLROnPlateau(patience=3, factor=0.5, monitor=\"val_loss\"),\n",
    "        checkpoint_cb  # <-- added\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Track how many epochs were actually trained\n",
    "last_epoch = len(history_1.history['loss'])\n",
    "\n",
    "# --- Unfreeze last Inception blocks ---\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "unfreeze = False\n",
    "for layer in base.layers:\n",
    "    if layer.name in [\"mixed9\", \"mixed10\"]:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        layer.trainable = True\n",
    "\n",
    "# Re-compile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# --- Fine-tuning training ---\n",
    "history_2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch=last_epoch,\n",
    "    epochs=last_epoch + 50,   # extend training\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "        ReduceLROnPlateau(patience=2, factor=0.5, monitor=\"val_loss\"),\n",
    "        checkpoint_cb  # <-- added\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Results</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:46:01.747923Z",
     "iopub.status.busy": "2025-08-29T10:46:01.747360Z",
     "iopub.status.idle": "2025-08-29T10:46:01.753998Z",
     "shell.execute_reply": "2025-08-29T10:46:01.752983Z",
     "shell.execute_reply.started": "2025-08-29T10:46:01.747888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = history_1.history['accuracy'] + history_2.history['accuracy'] \n",
    "val_acc = history_1.history['val_accuracy'] + history_2.history['val_accuracy'] \n",
    "\n",
    "loss = history_1.history['loss'] + history_2.history['loss'] \n",
    "val_loss = history_1.history['val_loss'] + history_2.history['val_loss'] \n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:52:48.074313Z",
     "iopub.status.busy": "2025-08-29T10:52:48.073560Z",
     "iopub.status.idle": "2025-08-29T10:52:48.082301Z",
     "shell.execute_reply": "2025-08-29T10:52:48.081356Z",
     "shell.execute_reply.started": "2025-08-29T10:52:48.074287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine histories\n",
    "acc = history_1.history['accuracy'] + history_2.history['accuracy']\n",
    "val_acc = history_1.history['val_accuracy'] + history_2.history['val_accuracy']\n",
    "loss = history_1.history['loss'] + history_2.history['loss']\n",
    "val_loss = history_1.history['val_loss'] + history_2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Create DataFrame\n",
    "history_df = pd.DataFrame({\n",
    "    \"epoch\": epochs,\n",
    "    \"accuracy\": acc,\n",
    "    \"val_accuracy\": val_acc,\n",
    "    \"loss\": loss,\n",
    "    \"val_loss\": val_loss\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "history_df.to_csv(\"combined_history_inceptionV3.csv\", index=False)\n",
    "\n",
    "print(\"✅ Training history saved to combined_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:46:04.932864Z",
     "iopub.status.busy": "2025-08-29T10:46:04.932254Z",
     "iopub.status.idle": "2025-08-29T10:46:08.958864Z",
     "shell.execute_reply": "2025-08-29T10:46:08.957827Z",
     "shell.execute_reply.started": "2025-08-29T10:46:04.932837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "num_epochs = epochs\n",
    "\n",
    "# X ticks positions (integers from 0 to num_epochs, step 4)\n",
    "xticks = range(0, len(epochs) + 2, 4)\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0].plot(epochs, acc, label='Train Accuracy')\n",
    "axs[0].plot(epochs, val_acc, label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch', fontsize=20)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=20)\n",
    "axs[0].set_title('Training and Validation Accuracy - InceptionV3', fontsize=22)\n",
    "axs[0].legend(fontsize=18)\n",
    "axs[0].set_xticks(xticks)\n",
    "axs[0].set_yticks(np.arange(0.2, 1.0, 0.1))\n",
    "axs[0].tick_params(axis='x', labelsize=18)\n",
    "axs[0].tick_params(axis='y', labelsize=18)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axs[1].plot(epochs, loss, label='Train Loss')\n",
    "axs[1].plot(epochs, val_loss, label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch', fontsize=20)\n",
    "axs[1].set_ylabel('Loss', fontsize=20)\n",
    "axs[1].set_title('Training and Validation Loss - InceptionV3', fontsize=22)\n",
    "axs[1].legend(fontsize=18)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].set_yticks(np.arange(0.5,2.75,0.25))\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "axs[1].tick_params(axis='y', labelsize=18)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig('InceptionV3_training_curves.png', dpi=600)\n",
    "plt.savefig('InceptionV3_training_curves.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T10:46:48.306653Z",
     "iopub.status.busy": "2025-08-29T10:46:48.305232Z",
     "iopub.status.idle": "2025-08-29T10:47:50.317046Z",
     "shell.execute_reply": "2025-08-29T10:47:50.316358Z",
     "shell.execute_reply.started": "2025-08-29T10:46:48.306595Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# 1. Get true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 2. Compute confusion matrix and metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "\n",
    "# 3. Plot confusion matrix\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels= class_names, yticklabels= class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('InceptionV3_confusion_matrix.png', dpi=600)\n",
    "plt.savefig('InceptionV3_confusion_matrix.pdf')\n",
    "plt.show()\n",
    "\n",
    "# 4. Save metrics to CSV\n",
    "metrics = {\n",
    "    'Accuracy': [accuracy],\n",
    "    'Recall': [recall],\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'MCC':[mcc]\n",
    "}\n",
    "\n",
    "# Save confusion matrix as CSV\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "df_cm.to_csv(\"confusion_inceptionv3.csv\")\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv('InceptionV3_performance_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Zipping all Files</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/output_files_inceptionv3_trainable.zip /kaggle/working/*"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8131776,
     "sourceId": 12856417,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
