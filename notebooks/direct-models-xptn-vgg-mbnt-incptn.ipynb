{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Importing Libraries</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-23T05:49:57.532968Z",
     "iopub.status.busy": "2025-08-23T05:49:57.532349Z",
     "iopub.status.idle": "2025-08-23T05:50:46.553175Z",
     "shell.execute_reply": "2025-08-23T05:50:46.552245Z",
     "shell.execute_reply.started": "2025-08-23T05:49:57.532934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T05:18:34.403682Z",
     "iopub.status.busy": "2025-08-31T05:18:34.403292Z",
     "iopub.status.idle": "2025-08-31T05:18:44.488829Z",
     "shell.execute_reply": "2025-08-31T05:18:44.488002Z",
     "shell.execute_reply.started": "2025-08-31T05:18:34.403621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "#from imblearn.metrics import geometric_mean_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Dataset Loading</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T05:18:44.490308Z",
     "iopub.status.busy": "2025-08-31T05:18:44.489757Z",
     "iopub.status.idle": "2025-08-31T05:18:44.495138Z",
     "shell.execute_reply": "2025-08-31T05:18:44.494135Z",
     "shell.execute_reply.started": "2025-08-31T05:18:44.490283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/input/51-skin-disease/Best_50_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T05:18:44.496580Z",
     "iopub.status.busy": "2025-08-31T05:18:44.496224Z",
     "iopub.status.idle": "2025-08-31T05:19:07.808213Z",
     "shell.execute_reply": "2025-08-31T05:19:07.807106Z",
     "shell.execute_reply.started": "2025-08-31T05:18:44.496547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root= dataset_path)\n",
    "class_names = dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T05:19:07.811749Z",
     "iopub.status.busy": "2025-08-31T05:19:07.811230Z",
     "iopub.status.idle": "2025-08-31T05:19:07.820638Z",
     "shell.execute_reply": "2025-08-31T05:19:07.819265Z",
     "shell.execute_reply.started": "2025-08-31T05:19:07.811717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset.targets has numeric labels for each image\n",
    "counts = Counter(dataset.targets)\n",
    "\n",
    "# Map counts to class names\n",
    "for class_idx, count in counts.items():\n",
    "    print(f\"{dataset.classes[class_idx]}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:18:59.528790Z",
     "iopub.status.busy": "2025-08-31T04:18:59.528592Z",
     "iopub.status.idle": "2025-08-31T04:18:59.598822Z",
     "shell.execute_reply": "2025-08-31T04:18:59.598266Z",
     "shell.execute_reply.started": "2025-08-31T04:18:59.528776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_counts = pd.DataFrame({\n",
    "    \"Class\": [dataset.classes[idx] for idx in counts.keys()],\n",
    "    \"Count\": [counts[idx] for idx in counts.keys()]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_counts.to_csv(\"class_counts.csv\", index=False)\n",
    "\n",
    "print(\"Counts saved to class_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Xception</b></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Dataset Splitting</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T05:19:07.822244Z",
     "iopub.status.busy": "2025-08-31T05:19:07.821894Z",
     "iopub.status.idle": "2025-08-31T05:19:12.964040Z",
     "shell.execute_reply": "2025-08-31T05:19:12.963072Z",
     "shell.execute_reply.started": "2025-08-31T05:19:07.822214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "# =========================\n",
    "# Dataset creation\n",
    "# =========================\n",
    "data_dir = dataset_path\n",
    "img_size = (299, 299)\n",
    "batch_size = 32\n",
    "\n",
    "# 70% train+val pool\n",
    "train_val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,   # leave 30% for val+test\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# 30% (val+test pool)\n",
    "val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Split val_test_ds into 15% val and 15% test\n",
    "val_test_size = val_test_ds.cardinality().numpy()\n",
    "val_size = val_test_size // 2\n",
    "test_size = val_test_size - val_size\n",
    "\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "train_ds = train_val_ds  # already 70%\n",
    "\n",
    "# =========================\n",
    "# Preprocessing\n",
    "# =========================\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess_batch(images, labels):\n",
    "    images = preprocess_input(images)\n",
    "    return images, labels\n",
    "\n",
    "train_ds = train_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "test_ds  = test_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T05:19:12.965168Z",
     "iopub.status.busy": "2025-08-31T05:19:12.964894Z",
     "iopub.status.idle": "2025-08-31T05:19:12.973046Z",
     "shell.execute_reply": "2025-08-31T05:19:12.972115Z",
     "shell.execute_reply.started": "2025-08-31T05:19:12.965146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32  # Use the same batch size you set\n",
    "\n",
    "def dataset_size(dataset):\n",
    "    # Get number of batches\n",
    "    batches = dataset.cardinality().numpy()\n",
    "    if batches == tf.data.INFINITE_CARDINALITY or batches == tf.data.UNKNOWN_CARDINALITY:\n",
    "        return \"Unknown size\"\n",
    "    else:\n",
    "        return batches * batch_size\n",
    "\n",
    "print(\"Train set size:\", dataset_size(train_ds))\n",
    "print(\"Validation set size:\", dataset_size(val_ds))\n",
    "print(\"Test set size:\", dataset_size(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Compiling</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T05:52:42.784086Z",
     "iopub.status.busy": "2025-08-23T05:52:42.783339Z",
     "iopub.status.idle": "2025-08-23T05:52:42.787403Z",
     "shell.execute_reply": "2025-08-23T05:52:42.786858Z",
     "shell.execute_reply.started": "2025-08-23T05:52:42.784059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T05:52:44.985533Z",
     "iopub.status.busy": "2025-08-23T05:52:44.985238Z",
     "iopub.status.idle": "2025-08-23T05:52:47.579834Z",
     "shell.execute_reply": "2025-08-23T05:52:47.578971Z",
     "shell.execute_reply.started": "2025-08-23T05:52:44.985512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "# =========================\n",
    "# Model creation\n",
    "# =========================\n",
    "num_classes = len(train_val_ds.class_names)\n",
    "\n",
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(img_size[0], img_size[1], 3)\n",
    ")\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T05:52:55.649432Z",
     "iopub.status.busy": "2025-08-23T05:52:55.648893Z",
     "iopub.status.idle": "2025-08-23T05:52:55.657292Z",
     "shell.execute_reply": "2025-08-23T05:52:55.656599Z",
     "shell.execute_reply.started": "2025-08-23T05:52:55.649394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor\n",
    "    patience=5,              # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_xception.h5',        # File path to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=True,    # Save only when improvement\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Training</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T05:52:58.775880Z",
     "iopub.status.busy": "2025-08-23T05:52:58.775614Z",
     "iopub.status.idle": "2025-08-23T05:56:30.018916Z",
     "shell.execute_reply": "2025-08-23T05:56:30.018310Z",
     "shell.execute_reply.started": "2025-08-23T05:52:58.775858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b1>Results</b1></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T05:58:08.472249Z",
     "iopub.status.busy": "2025-08-23T05:58:08.471967Z",
     "iopub.status.idle": "2025-08-23T05:58:08.486283Z",
     "shell.execute_reply": "2025-08-23T05:58:08.485689Z",
     "shell.execute_reply.started": "2025-08-23T05:58:08.472227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hist_training_xception=pd.DataFrame(history.history)\n",
    "hist_training_xception\n",
    "# Save to CSV\n",
    "hist_training_xception.to_csv(\"hist_training_xception.csv\", index=False)\n",
    "print(\"XCeption Training history to hist_training_xception.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:00:45.335768Z",
     "iopub.status.busy": "2025-08-23T06:00:45.334406Z",
     "iopub.status.idle": "2025-08-23T06:00:48.351070Z",
     "shell.execute_reply": "2025-08-23T06:00:48.350356Z",
     "shell.execute_reply.started": "2025-08-23T06:00:45.335740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "num_epochs = len(history.history['accuracy'])  # total epochs trained\n",
    "\n",
    "# X ticks positions (integers from 0 to num_epochs, step 4)\n",
    "xticks = range(0, num_epochs + 1, 4)\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch', fontsize=20)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=20)\n",
    "axs[0].set_title('Training and Validation Accuracy - Xception', fontsize=22)\n",
    "axs[0].legend(fontsize=18)\n",
    "axs[0].set_xticks(xticks)\n",
    "axs[0].tick_params(axis='x', labelsize=18)\n",
    "axs[0].tick_params(axis='y', labelsize=18)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axs[1].plot(history.history['loss'], label='Train Loss')\n",
    "axs[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch', fontsize=20)\n",
    "axs[1].set_ylabel('Loss', fontsize=20)\n",
    "axs[1].set_title('Training and Validation Loss - Xception', fontsize=22)\n",
    "axs[1].legend(fontsize=18)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "axs[1].tick_params(axis='y', labelsize=18)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig('xception_training_curves.png', dpi=600)\n",
    "plt.savefig('xception_training_curves.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:01:26.481465Z",
     "iopub.status.busy": "2025-08-23T06:01:26.481156Z",
     "iopub.status.idle": "2025-08-23T06:02:41.052871Z",
     "shell.execute_reply": "2025-08-23T06:02:41.052171Z",
     "shell.execute_reply.started": "2025-08-23T06:01:26.481437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# 1. Get true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 2. Compute confusion matrix and metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "\n",
    "# 3. Plot confusion matrix\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels= class_names, yticklabels= class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('xception_confusion_matrix.png', dpi=600)\n",
    "plt.savefig('xception_confusion_matrix.pdf')\n",
    "plt.show()\n",
    "\n",
    "# 4. Save metrics to CSV\n",
    "metrics = {\n",
    "    'Accuracy': [accuracy],\n",
    "    'Recall': [recall],\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'MCC':[mcc]\n",
    "}\n",
    "# Save confusion matrix as CSV\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "df_cm.to_csv(\"confusion_matrix_xception.csv\")\n",
    "\n",
    "df_metrics_xception = pd.DataFrame(metrics)\n",
    "df_metrics_xception.to_csv('performance_metrics_xception.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>GradCam Analysis</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CPU to run the GradCam analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:02:43.676616Z",
     "iopub.status.busy": "2025-08-31T06:02:43.675501Z",
     "iopub.status.idle": "2025-08-31T06:02:43.681877Z",
     "shell.execute_reply": "2025-08-31T06:02:43.680717Z",
     "shell.execute_reply.started": "2025-08-31T06:02:43.676586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:02:46.003117Z",
     "iopub.status.busy": "2025-08-31T06:02:46.002810Z",
     "iopub.status.idle": "2025-08-31T06:02:46.008212Z",
     "shell.execute_reply": "2025-08-31T06:02:46.007245Z",
     "shell.execute_reply.started": "2025-08-31T06:02:46.003088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (299, 299)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:26:26.256625Z",
     "iopub.status.busy": "2025-08-31T06:26:26.256281Z",
     "iopub.status.idle": "2025-08-31T06:26:26.276414Z",
     "shell.execute_reply": "2025-08-31T06:26:26.275389Z",
     "shell.execute_reply.started": "2025-08-31T06:26:26.256601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The local path to our target image\n",
    "img_path = \"/kaggle/input/51-skin-disease/Best_50_class/folliculitis/folliculitis/fitzdamin11243.jpg\"\n",
    "\n",
    "from PIL import Image as PILImage  # PIL's Image\n",
    "from IPython.display import Image, display  # IPython's Image\n",
    "\n",
    "# Load the image with PIL\n",
    "img = PILImage.open(img_path)\n",
    "\n",
    "# Save in a new location\n",
    "img.save(\"/kaggle/working/original_image.jpg\")\n",
    "\n",
    "# Display in notebook\n",
    "display(Image(img_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grad-CAM algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:26:28.862822Z",
     "iopub.status.busy": "2025-08-31T06:26:28.862452Z",
     "iopub.status.idle": "2025-08-31T06:26:28.875650Z",
     "shell.execute_reply": "2025-08-31T06:26:28.874511Z",
     "shell.execute_reply.started": "2025-08-31T06:26:28.862797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.utils.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:26:31.737963Z",
     "iopub.status.busy": "2025-08-31T06:26:31.737597Z",
     "iopub.status.idle": "2025-08-31T06:26:36.458677Z",
     "shell.execute_reply": "2025-08-31T06:26:36.457766Z",
     "shell.execute_reply.started": "2025-08-31T06:26:31.737936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "\n",
    "# Make model\n",
    "model = model_builder(weights=\"imagenet\")\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(img_array)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.savefig(\"gradcam_heatmap.png\", dpi=300)   # Save as PNG\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a superimposed visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:26:36.460652Z",
     "iopub.status.busy": "2025-08-31T06:26:36.460333Z",
     "iopub.status.idle": "2025-08-31T06:26:36.475827Z",
     "shell.execute_reply": "2025-08-31T06:26:36.474935Z",
     "shell.execute_reply.started": "2025-08-31T06:26:36.460629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"superimposed.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.utils.load_img(img_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:27:34.736136Z",
     "iopub.status.busy": "2025-08-31T06:27:34.735794Z",
     "iopub.status.idle": "2025-08-31T06:27:42.572524Z",
     "shell.execute_reply": "2025-08-31T06:27:42.571562Z",
     "shell.execute_reply.started": "2025-08-31T06:27:34.736111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # Make sure this is PIL.Image\n",
    "\n",
    "# Paths to your images\n",
    "original_image_path = img_path\n",
    "heatmap_path = \"/kaggle/working/gradcam_heatmap.png\"\n",
    "superimposed_path = \"/kaggle/working/superimposed.jpg\"\n",
    "\n",
    "# Load images using PIL\n",
    "original_img = Image.open(original_image_path)\n",
    "heatmap_img = Image.open(heatmap_path)\n",
    "superimposed_img = Image.open(superimposed_path)\n",
    "\n",
    "# Create subplot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle(\"Grad-CAM Visualization-Folliculitis\", fontsize=18)\n",
    "\n",
    "axes[0].imshow(original_img)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(heatmap_img)\n",
    "axes[1].set_title(\"Grad-CAM Heatmap\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(superimposed_img)\n",
    "axes[2].set_title(\"Superimposed Image\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "# Save the figure \n",
    "fig.savefig(\"/kaggle/working/gradcam_subplot_Folliculitis.jpg\", dpi=600, bbox_inches='tight')\n",
    "fig.savefig(\"/kaggle/working/gradcam_subplot_Folliculitis.pdf\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T06:23:44.576076Z",
     "iopub.status.busy": "2025-08-31T06:23:44.575699Z",
     "iopub.status.idle": "2025-08-31T06:23:44.584910Z",
     "shell.execute_reply": "2025-08-31T06:23:44.583969Z",
     "shell.execute_reply.started": "2025-08-31T06:23:44.576041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# from zipfile import ZipFile\n",
    "\n",
    "# working_dir = \"/kaggle/working/\"\n",
    "\n",
    "# # ---------------------------\n",
    "# # Step 1: Delete everything in the directory\n",
    "# # ---------------------------\n",
    "# for filename in os.listdir(working_dir):\n",
    "#     file_path = os.path.join(working_dir, filename)\n",
    "#     try:\n",
    "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "#             os.unlink(file_path)  # remove file or symlink\n",
    "#         elif os.path.isdir(file_path):\n",
    "#             shutil.rmtree(file_path)  # remove directory and contents\n",
    "#     except Exception as e:\n",
    "#         print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "# print(\"All contents deleted from /kaggle/working/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>VGG16</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Dataset Splitting</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:22:36.483475Z",
     "iopub.status.busy": "2025-08-23T06:22:36.483188Z",
     "iopub.status.idle": "2025-08-23T06:22:46.532840Z",
     "shell.execute_reply": "2025-08-23T06:22:46.532077Z",
     "shell.execute_reply.started": "2025-08-23T06:22:36.483455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data_dir = dataset_path\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# =========================\n",
    "# Step 1: 70% training set\n",
    "# =========================\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,   # leave 30% for val+test\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 2: 30% val+test pool\n",
    "# =========================\n",
    "val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 3: Split val_test_ds into 15% val + 15% test\n",
    "# =========================\n",
    "val_test_size = val_test_ds.cardinality().numpy()\n",
    "val_size = val_test_size // 2\n",
    "test_size = val_test_size - val_size  # handles odd numbers safely\n",
    "\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:22:49.288890Z",
     "iopub.status.busy": "2025-08-23T06:22:49.288598Z",
     "iopub.status.idle": "2025-08-23T06:22:49.295269Z",
     "shell.execute_reply": "2025-08-23T06:22:49.294464Z",
     "shell.execute_reply.started": "2025-08-23T06:22:49.288867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32  # Use the same batch size you set\n",
    "\n",
    "def dataset_size(dataset):\n",
    "    # Get number of batches\n",
    "    batches = dataset.cardinality().numpy()\n",
    "    if batches == tf.data.INFINITE_CARDINALITY or batches == tf.data.UNKNOWN_CARDINALITY:\n",
    "        return \"Unknown size\"\n",
    "    else:\n",
    "        return batches * batch_size\n",
    "\n",
    "print(\"Train set size:\", dataset_size(train_ds))\n",
    "print(\"Validation set size:\", dataset_size(val_ds))\n",
    "print(\"Test set size:\", dataset_size(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Compiling</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:24:17.753558Z",
     "iopub.status.busy": "2025-08-23T06:24:17.753264Z",
     "iopub.status.idle": "2025-08-23T06:24:18.362049Z",
     "shell.execute_reply": "2025-08-23T06:24:18.361453Z",
     "shell.execute_reply.started": "2025-08-23T06:24:17.753535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load VGG16 without top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze convolutional base\n",
    "\n",
    "# Build model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:27:13.940076Z",
     "iopub.status.busy": "2025-08-23T06:27:13.939271Z",
     "iopub.status.idle": "2025-08-23T06:27:13.944503Z",
     "shell.execute_reply": "2025-08-23T06:27:13.943884Z",
     "shell.execute_reply.started": "2025-08-23T06:27:13.940050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor\n",
    "    patience=5,              # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_vgg16.h5',        # File path to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=True,    # Save only when improvement\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Training</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:27:17.347133Z",
     "iopub.status.busy": "2025-08-23T06:27:17.346877Z",
     "iopub.status.idle": "2025-08-23T06:29:56.791884Z",
     "shell.execute_reply": "2025-08-23T06:29:56.791106Z",
     "shell.execute_reply.started": "2025-08-23T06:27:17.347115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint]   # Include both callbacks here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Results</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:30:21.968069Z",
     "iopub.status.busy": "2025-08-23T06:30:21.967391Z",
     "iopub.status.idle": "2025-08-23T06:30:21.974372Z",
     "shell.execute_reply": "2025-08-23T06:30:21.973755Z",
     "shell.execute_reply.started": "2025-08-23T06:30:21.968043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hist_training_vgg16=pd.DataFrame(history.history)\n",
    "hist_training_vgg16\n",
    "# Save to CSV\n",
    "hist_training_vgg16.to_csv(\"hist_training_vgg16.csv\", index=False)\n",
    "print(\"VGG16 Training history to hist_training_vgg16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:30:26.407279Z",
     "iopub.status.busy": "2025-08-23T06:30:26.407023Z",
     "iopub.status.idle": "2025-08-23T06:30:29.300163Z",
     "shell.execute_reply": "2025-08-23T06:30:29.299475Z",
     "shell.execute_reply.started": "2025-08-23T06:30:26.407259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "num_epochs = len(history.history['accuracy'])  # total epochs trained\n",
    "\n",
    "# X ticks positions (integers from 0 to num_epochs, step 4)\n",
    "xticks = range(0, num_epochs + 1, 4)\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch', fontsize=20)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=20)\n",
    "axs[0].set_title('Training and Validation Accuracy - VGG16', fontsize=22)\n",
    "axs[0].legend(fontsize=18)\n",
    "axs[0].set_xticks(xticks)\n",
    "axs[0].tick_params(axis='x', labelsize=18)\n",
    "axs[0].tick_params(axis='y', labelsize=18)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axs[1].plot(history.history['loss'], label='Train Loss')\n",
    "axs[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch', fontsize=20)\n",
    "axs[1].set_ylabel('Loss', fontsize=20)\n",
    "axs[1].set_title('Training and Validation Loss - VGG-16', fontsize=22)\n",
    "axs[1].legend(fontsize=18)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "axs[1].tick_params(axis='y', labelsize=18)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig('vgg16_training_curves.png', dpi=600)\n",
    "plt.savefig('vgg16_training_curves.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:32:41.093463Z",
     "iopub.status.busy": "2025-08-23T06:32:41.093158Z",
     "iopub.status.idle": "2025-08-23T06:33:37.285850Z",
     "shell.execute_reply": "2025-08-23T06:33:37.285133Z",
     "shell.execute_reply.started": "2025-08-23T06:32:41.093431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# 1. Get true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 2. Compute confusion matrix and metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "\n",
    "# 3. Plot confusion matrix\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels= class_names, yticklabels= class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('vgg16_confusion_matrix.png', dpi=600)\n",
    "plt.savefig('vgg16_confusion_matrix.pdf')\n",
    "plt.show()\n",
    "\n",
    "# 4. Save metrics to CSV\n",
    "metrics = {\n",
    "    'Accuracy': [accuracy],\n",
    "    'Recall': [recall],\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'MCC':[mcc]\n",
    "}\n",
    "# Save confusion matrix as CSV\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "df_cm.to_csv(\"confusion_matrix_vgg16.csv\")\n",
    "\n",
    "df_metrics_vgg16 = pd.DataFrame(metrics)\n",
    "df_metrics_vgg16.to_csv('performance_metrics_vgg16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>MobileNetV2</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Compiling</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:39:29.193483Z",
     "iopub.status.busy": "2025-08-23T06:39:29.192804Z",
     "iopub.status.idle": "2025-08-23T06:39:30.403128Z",
     "shell.execute_reply": "2025-08-23T06:39:30.402328Z",
     "shell.execute_reply.started": "2025-08-23T06:39:29.193458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load MobileNetV2 without the top classifier layers\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze base model layers if you want to train only classifier first\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)   # extra dense layer\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(num_classes, activation='softmax')(x)  \n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:41:13.130720Z",
     "iopub.status.busy": "2025-08-23T06:41:13.130397Z",
     "iopub.status.idle": "2025-08-23T06:41:13.134943Z",
     "shell.execute_reply": "2025-08-23T06:41:13.134179Z",
     "shell.execute_reply.started": "2025-08-23T06:41:13.130696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor\n",
    "    patience=5,              # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_mobilenetv2.h5',        # File path to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=True,    # Save only when improvement\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Training</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:41:16.104269Z",
     "iopub.status.busy": "2025-08-23T06:41:16.103978Z",
     "iopub.status.idle": "2025-08-23T06:42:17.030380Z",
     "shell.execute_reply": "2025-08-23T06:42:17.029803Z",
     "shell.execute_reply.started": "2025-08-23T06:41:16.104245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Results</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:43:23.417310Z",
     "iopub.status.busy": "2025-08-23T06:43:23.417040Z",
     "iopub.status.idle": "2025-08-23T06:43:23.424022Z",
     "shell.execute_reply": "2025-08-23T06:43:23.423419Z",
     "shell.execute_reply.started": "2025-08-23T06:43:23.417289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hist_training_mobilenetv2=pd.DataFrame(history.history)\n",
    "hist_training_mobilenetv2\n",
    "# Save to CSV\n",
    "hist_training_vgg16.to_csv(\"hist_training_mobilenetv2.csv\", index=False)\n",
    "print(\"MobileNetv2 Training history to hist_training_mobilenetv2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:44:30.470306Z",
     "iopub.status.busy": "2025-08-23T06:44:30.470007Z",
     "iopub.status.idle": "2025-08-23T06:44:33.464186Z",
     "shell.execute_reply": "2025-08-23T06:44:33.463384Z",
     "shell.execute_reply.started": "2025-08-23T06:44:30.470284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "num_epochs = len(history.history['accuracy'])  # total epochs trained\n",
    "\n",
    "# X ticks positions (integers from 0 to num_epochs, step 4)\n",
    "xticks = range(0, num_epochs + 1, 4)\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch', fontsize=20)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=20)\n",
    "axs[0].set_title('Training and Validation Accuracy - MobileNetV2', fontsize=22)\n",
    "axs[0].legend(fontsize=18)\n",
    "axs[0].set_xticks(xticks)\n",
    "axs[0].tick_params(axis='x', labelsize=18)\n",
    "axs[0].tick_params(axis='y', labelsize=18)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axs[1].plot(history.history['loss'], label='Train Loss')\n",
    "axs[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch', fontsize=20)\n",
    "axs[1].set_ylabel('Loss', fontsize=20)\n",
    "axs[1].set_title('Training and Validation Loss - MobileNetV2', fontsize=22)\n",
    "axs[1].legend(fontsize=18)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "axs[1].tick_params(axis='y', labelsize=18)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig('mobilenetv2_training_curves.png', dpi=600)\n",
    "plt.savefig('mobilenet_training_curves.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:46:30.588031Z",
     "iopub.status.busy": "2025-08-23T06:46:30.587729Z",
     "iopub.status.idle": "2025-08-23T06:47:05.362582Z",
     "shell.execute_reply": "2025-08-23T06:47:05.361905Z",
     "shell.execute_reply.started": "2025-08-23T06:46:30.588008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# 1. Get true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 2. Compute confusion matrix and metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "\n",
    "# 3. Plot confusion matrix\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels= class_names, yticklabels= class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mobilenetv2_confusion_matrix.png', dpi=600)\n",
    "plt.savefig('mobilenetv2_confusion_matrix.pdf')\n",
    "plt.show()\n",
    "\n",
    "# 4. Save metrics to CSV\n",
    "metrics = {\n",
    "    'Accuracy': [accuracy],\n",
    "    'Recall': [recall],\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'MCC':[mcc]\n",
    "}\n",
    "# Save confusion matrix as CSV\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "df_cm.to_csv(\"confusion_matrix_mobilenet.csv\")\n",
    "\n",
    "df_metrics_mobilenet = pd.DataFrame(metrics)\n",
    "df_metrics_mobilenet.to_csv('performance_metrics_mobilenetv2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>InceptionV3</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Datset Splitting</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:55:01.624344Z",
     "iopub.status.busy": "2025-08-31T04:55:01.624064Z",
     "iopub.status.idle": "2025-08-31T04:55:06.321264Z",
     "shell.execute_reply": "2025-08-31T04:55:06.320613Z",
     "shell.execute_reply.started": "2025-08-31T04:55:01.624310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "# =========================\n",
    "# Dataset creation\n",
    "# =========================\n",
    "data_dir = dataset_path  # your dataset folder\n",
    "img_size = (299, 299)    # InceptionV3 expects 299x299\n",
    "batch_size = 32\n",
    "\n",
    "# =========================\n",
    "# Step 1: 70% training set\n",
    "# =========================\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,   # leave 30% for val+test\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 2: 30% val+test pool\n",
    "# =========================\n",
    "val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.30,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 3: Split val_test_ds into 15% val + 15% test\n",
    "# =========================\n",
    "val_test_size = val_test_ds.cardinality().numpy()\n",
    "val_size = val_test_size // 2\n",
    "test_size = val_test_size - val_size  # handles odd numbers safely\n",
    "\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "# =========================\n",
    "# Preprocessing function\n",
    "# =========================\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess_batch(images, labels):\n",
    "    images = preprocess_input(images)  # Apply InceptionV3 preprocessing\n",
    "    return images, labels\n",
    "\n",
    "train_ds = train_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:55:06.322720Z",
     "iopub.status.busy": "2025-08-31T04:55:06.322442Z",
     "iopub.status.idle": "2025-08-31T04:55:06.328320Z",
     "shell.execute_reply": "2025-08-31T04:55:06.327676Z",
     "shell.execute_reply.started": "2025-08-31T04:55:06.322692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32  # Use the same batch size you set\n",
    "\n",
    "def dataset_size(dataset):\n",
    "    # Get number of batches\n",
    "    batches = dataset.cardinality().numpy()\n",
    "    if batches == tf.data.INFINITE_CARDINALITY or batches == tf.data.UNKNOWN_CARDINALITY:\n",
    "        return \"Unknown size\"\n",
    "    else:\n",
    "        return batches * batch_size\n",
    "\n",
    "print(\"Train set size:\", dataset_size(train_ds))\n",
    "print(\"Validation set size:\", dataset_size(val_ds))\n",
    "print(\"Test set size:\", dataset_size(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Compiling</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:55:31.995099Z",
     "iopub.status.busy": "2025-08-23T06:55:31.993987Z",
     "iopub.status.idle": "2025-08-23T06:55:34.230676Z",
     "shell.execute_reply": "2025-08-23T06:55:34.230070Z",
     "shell.execute_reply.started": "2025-08-23T06:55:31.995073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "# =========================\n",
    "# Model setup (Transfer Learning)\n",
    "# =========================\n",
    "base_model = InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(299, 299, 3)\n",
    ")\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(train_val_ds.class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:55:52.416091Z",
     "iopub.status.busy": "2025-08-23T06:55:52.415521Z",
     "iopub.status.idle": "2025-08-23T06:55:52.434434Z",
     "shell.execute_reply": "2025-08-23T06:55:52.433900Z",
     "shell.execute_reply.started": "2025-08-23T06:55:52.416065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:57:37.005776Z",
     "iopub.status.busy": "2025-08-23T06:57:37.004852Z",
     "iopub.status.idle": "2025-08-23T06:57:37.010268Z",
     "shell.execute_reply": "2025-08-23T06:57:37.009403Z",
     "shell.execute_reply.started": "2025-08-23T06:57:37.005729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Metric to monitor\n",
    "    patience=5,              # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_inceptionv3.h5',        # File path to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=True,    # Save only when improvement\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Model Training</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:57:46.405056Z",
     "iopub.status.busy": "2025-08-23T06:57:46.404768Z",
     "iopub.status.idle": "2025-08-23T06:59:19.783226Z",
     "shell.execute_reply": "2025-08-23T06:59:19.782429Z",
     "shell.execute_reply.started": "2025-08-23T06:57:46.405033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Results</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T06:59:34.107271Z",
     "iopub.status.busy": "2025-08-23T06:59:34.106637Z",
     "iopub.status.idle": "2025-08-23T06:59:34.112759Z",
     "shell.execute_reply": "2025-08-23T06:59:34.112063Z",
     "shell.execute_reply.started": "2025-08-23T06:59:34.107246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hist_training_inceptionv3=pd.DataFrame(history.history)\n",
    "hist_training_inceptionv3\n",
    "# Save to CSV\n",
    "hist_training_inceptionv3.to_csv(\"hist_training_inceptionv3.csv\", index=False)\n",
    "print(\"InceptionV3 Training history to hist_training_inceptionv3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T07:00:31.169511Z",
     "iopub.status.busy": "2025-08-23T07:00:31.168954Z",
     "iopub.status.idle": "2025-08-23T07:00:34.089190Z",
     "shell.execute_reply": "2025-08-23T07:00:34.088531Z",
     "shell.execute_reply.started": "2025-08-23T07:00:31.169486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sections to modify\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "num_epochs = len(history.history['accuracy'])  # total epochs trained\n",
    "\n",
    "# X ticks positions (integers from 0 to num_epochs, step 4)\n",
    "xticks = range(0, num_epochs + 1, 4)\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch', fontsize=20)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=20)\n",
    "axs[0].set_title('Training and Validation Accuracy - InceptionV3', fontsize=22)\n",
    "axs[0].legend(fontsize=18)\n",
    "axs[0].set_xticks(xticks)\n",
    "axs[0].tick_params(axis='x', labelsize=18)\n",
    "axs[0].tick_params(axis='y', labelsize=18)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axs[1].plot(history.history['loss'], label='Train Loss')\n",
    "axs[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch', fontsize=20)\n",
    "axs[1].set_ylabel('Loss', fontsize=20)\n",
    "axs[1].set_title('Training and Validation Loss - InceptionV3', fontsize=22)\n",
    "axs[1].legend(fontsize=18)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "axs[1].tick_params(axis='y', labelsize=18)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig('inceptionv3_training_curves.png', dpi=600)\n",
    "plt.savefig('inceptionv3_training_curves.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T07:01:56.973366Z",
     "iopub.status.busy": "2025-08-23T07:01:56.973104Z",
     "iopub.status.idle": "2025-08-23T07:02:57.380066Z",
     "shell.execute_reply": "2025-08-23T07:02:57.379246Z",
     "shell.execute_reply.started": "2025-08-23T07:01:56.973349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# 1. Get true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 2. Compute confusion matrix and metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "\n",
    "# 3. Plot confusion matrix\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels= class_names, yticklabels= class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('inceptionv3_confusion_matrix.png', dpi=600)\n",
    "plt.savefig('inceptionv3_confusion_matrix.pdf')\n",
    "plt.show()\n",
    "\n",
    "# 4. Save metrics to CSV\n",
    "metrics = {\n",
    "    'Accuracy': [accuracy],\n",
    "    'Recall': [recall],\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'MCC':[mcc]\n",
    "}\n",
    "# Save confusion matrix as CSV\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "df_cm.to_csv(\"confusion_inceptionv3.csv\")\n",
    "\n",
    "df_metrics_inceptionv3 = pd.DataFrame(metrics)\n",
    "df_metrics_inceptionv3.to_csv('performance_metrics_inceptionv3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Zipping all outputs</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T07:04:58.868145Z",
     "iopub.status.busy": "2025-08-23T07:04:58.867857Z",
     "iopub.status.idle": "2025-08-23T07:05:16.022690Z",
     "shell.execute_reply": "2025-08-23T07:05:16.021986Z",
     "shell.execute_reply.started": "2025-08-23T07:04:58.868124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/output_files_xception_vgg16_mobilenetv3_inceptionv.zip /kaggle/working/*"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8129685,
     "sourceId": 12853359,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
