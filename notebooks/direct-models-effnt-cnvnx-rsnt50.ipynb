{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12853359,"sourceType":"datasetVersion","datasetId":8129685}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><b>Importing Libraries</b></h1>","metadata":{}},{"cell_type":"code","source":"#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        os.path.join(dirname, filename)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:04:30.246503Z","iopub.execute_input":"2025-08-23T08:04:30.246860Z","iopub.status.idle":"2025-08-23T08:04:30.251449Z","shell.execute_reply.started":"2025-08-23T08:04:30.246820Z","shell.execute_reply":"2025-08-23T08:04:30.250605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom collections import Counter\nfrom tqdm import tqdm\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix , accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import recall_score, precision_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n#from imblearn.metrics import geometric_mean_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nfrom torchvision import datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T16:05:49.892653Z","iopub.execute_input":"2025-08-24T16:05:49.893166Z","iopub.status.idle":"2025-08-24T16:06:09.587119Z","shell.execute_reply.started":"2025-08-24T16:05:49.893140Z","shell.execute_reply":"2025-08-24T16:06:09.586496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><b>Dataset Loading</b></h1>","metadata":{}},{"cell_type":"code","source":"dataset_path = '/kaggle/input/51-skin-disease/Best_50_class'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T16:06:09.588295Z","iopub.execute_input":"2025-08-24T16:06:09.588805Z","iopub.status.idle":"2025-08-24T16:06:09.592273Z","shell.execute_reply.started":"2025-08-24T16:06:09.588776Z","shell.execute_reply":"2025-08-24T16:06:09.591562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = datasets.ImageFolder(root= dataset_path)\nclass_names = dataset.classes\nprint(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T16:06:09.592876Z","iopub.execute_input":"2025-08-24T16:06:09.593168Z","iopub.status.idle":"2025-08-24T16:06:50.317725Z","shell.execute_reply.started":"2025-08-24T16:06:09.593131Z","shell.execute_reply":"2025-08-24T16:06:50.317120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dataset.targets has numeric labels for each image\ncounts = Counter(dataset.targets)\n\n# Map counts to class names\nfor class_idx, count in counts.items():\n    print(f\"{dataset.classes[class_idx]}: {count} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T16:06:50.318859Z","iopub.execute_input":"2025-08-24T16:06:50.319091Z","iopub.status.idle":"2025-08-24T16:06:50.325316Z","shell.execute_reply.started":"2025-08-24T16:06:50.319066Z","shell.execute_reply":"2025-08-24T16:06:50.324566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_counts = pd.DataFrame({\n    \"Class\": [dataset.classes[idx] for idx in counts.keys()],\n    \"Count\": [counts[idx] for idx in counts.keys()]\n})\n\n# Save to CSV\ndf_counts.to_csv(\"class_counts.csv\", index=False)\n\nprint(\"Counts saved to class_counts.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T12:56:27.195057Z","iopub.execute_input":"2025-08-23T12:56:27.195338Z","iopub.status.idle":"2025-08-23T12:56:27.210109Z","shell.execute_reply.started":"2025-08-23T12:56:27.195319Z","shell.execute_reply":"2025-08-23T12:56:27.209438Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><b>EfficientNetB0</b></h1>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Datset Splitting</b></h2>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\nfrom tensorflow.keras import layers, models\n\n# =========================\n# Dataset creation\n# =========================\ndata_dir = dataset_path  # your dataset folder\nimg_size = (224, 224)    # EfficientNetB0 expects 224x224\nbatch_size = 32\n\n# =========================\n# Step 1: 70% training set\n# =========================\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.30,   # leave 30% for val+test\n    subset=\"training\",\n    seed=123,\n    image_size=img_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\n# =========================\n# Step 2: 30% val+test pool\n# =========================\nval_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.30,\n    subset=\"validation\",\n    seed=123,\n    image_size=img_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\n# =========================\n# Step 3: Split val_test_ds into 15% val + 15% test\n# =========================\nval_test_size = val_test_ds.cardinality().numpy()\nval_size = val_test_size // 2\ntest_size = val_test_size - val_size  # handles odd numbers safely\n\nval_ds = val_test_ds.take(val_size)\ntest_ds = val_test_ds.skip(val_size)\n\n# =========================\n# Preprocessing function\n# =========================\nAUTOTUNE = tf.data.AUTOTUNE\n\ndef preprocess_batch(images, labels):\n    images = preprocess_input(images)  # EfficientNetB0 preprocessing\n    return images, labels\n\ntrain_ds = train_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n\n# Prefetch for performance\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T17:31:01.823846Z","iopub.execute_input":"2025-08-23T17:31:01.824170Z","iopub.status.idle":"2025-08-23T17:31:05.359794Z","shell.execute_reply.started":"2025-08-23T17:31:01.824147Z","shell.execute_reply":"2025-08-23T17:31:05.359059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32  # Use the same batch size you set\n\ndef dataset_size(dataset):\n    # Get number of batches\n    batches = dataset.cardinality().numpy()\n    if batches == tf.data.INFINITE_CARDINALITY or batches == tf.data.UNKNOWN_CARDINALITY:\n        return \"Unknown size\"\n    else:\n        return batches * batch_size\n\nprint(\"Train set size:\", dataset_size(train_ds))\nprint(\"Validation set size:\", dataset_size(val_ds))\nprint(\"Test set size:\", dataset_size(test_ds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T17:31:10.665479Z","iopub.execute_input":"2025-08-23T17:31:10.666194Z","iopub.status.idle":"2025-08-23T17:31:10.671668Z","shell.execute_reply.started":"2025-08-23T17:31:10.666171Z","shell.execute_reply":"2025-08-23T17:31:10.670959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Model Compiling</b></h2>","metadata":{}},{"cell_type":"code","source":"# =========================\n# Model creation\n# =========================\nnum_classes = len(val_test_ds.class_names)\n\nbase_model = EfficientNetB0(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(img_size[0], img_size[1], 3)\n)\nbase_model.trainable = False  # Freeze base model\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:06:33.383421Z","iopub.execute_input":"2025-08-23T08:06:33.383652Z","iopub.status.idle":"2025-08-23T08:06:35.948877Z","shell.execute_reply.started":"2025-08-23T08:06:33.383628Z","shell.execute_reply":"2025-08-23T08:06:35.948360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',      # Metric to monitor\n    patience=5,              # Number of epochs with no improvement to wait\n    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n)\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\n    'best_model_efficientnetb0.h5',        # File path to save the model\n    monitor='val_loss',     # Metric to monitor\n    save_best_only=True,    # Save only when improvement\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:06:35.950442Z","iopub.execute_input":"2025-08-23T08:06:35.950627Z","iopub.status.idle":"2025-08-23T08:06:35.958002Z","shell.execute_reply.started":"2025-08-23T08:06:35.950614Z","shell.execute_reply":"2025-08-23T08:06:35.957506Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Model Training</b></h2>","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=50,\n    callbacks=[early_stopping, checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:06:35.958642Z","iopub.execute_input":"2025-08-23T08:06:35.958845Z","iopub.status.idle":"2025-08-23T08:08:33.992594Z","shell.execute_reply.started":"2025-08-23T08:06:35.958831Z","shell.execute_reply":"2025-08-23T08:08:33.991534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Results</b></h2>","metadata":{}},{"cell_type":"code","source":"hist_training_efficientnet=pd.DataFrame(history.history)\nhist_training_efficientnet\n# Save to CSV\nhist_training_efficientnet.to_csv(\"hist_training_efficientnet.csv\", index=False)\nprint(\"EfficientNetB0 Training history to hist_training_efficientnet.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:10:12.769751Z","iopub.execute_input":"2025-08-23T08:10:12.770288Z","iopub.status.idle":"2025-08-23T08:10:12.776075Z","shell.execute_reply.started":"2025-08-23T08:10:12.770263Z","shell.execute_reply":"2025-08-23T08:10:12.775383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sections to modify\nfig, axs = plt.subplots(1, 2, figsize=(20, 6))\n\nnum_epochs = len(history.history['accuracy'])  # total epochs trained\n\n# X ticks positions (integers from 0 to num_epochs, step 4)\nxticks = range(0, num_epochs + 1, 4)\n\n# Plot accuracy\naxs[0].plot(history.history['accuracy'], label='Train Accuracy')\naxs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\naxs[0].set_xlabel('Epoch', fontsize=20)\naxs[0].set_ylabel('Accuracy', fontsize=20)\naxs[0].set_title('Training and Validation Accuracy - EfficientNetB0', fontsize=22)\naxs[0].legend(fontsize=18)\naxs[0].set_xticks(xticks)\naxs[0].tick_params(axis='x', labelsize=18)\naxs[0].tick_params(axis='y', labelsize=18)\naxs[0].grid(True)\n\n# Plot loss\naxs[1].plot(history.history['loss'], label='Train Loss')\naxs[1].plot(history.history['val_loss'], label='Validation Loss')\naxs[1].set_xlabel('Epoch', fontsize=20)\naxs[1].set_ylabel('Loss', fontsize=20)\naxs[1].set_title('Training and Validation Loss - EfficientNetB0', fontsize=22)\naxs[1].legend(fontsize=18)\naxs[1].set_xticks(xticks)\naxs[1].tick_params(axis='x', labelsize=18)\naxs[1].tick_params(axis='y', labelsize=18)\naxs[1].grid(True)\n\nplt.tight_layout()\n\n# Save the combined figure\nplt.savefig('efficientnet_training_curves.png', dpi=600)\nplt.savefig('efficientnet_training_curves.pdf')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:10:16.747952Z","iopub.execute_input":"2025-08-23T08:10:16.748486Z","iopub.status.idle":"2025-08-23T08:10:20.585176Z","shell.execute_reply.started":"2025-08-23T08:10:16.748462Z","shell.execute_reply":"2025-08-23T08:10:20.584526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n\n# 1. Get true and predicted labels\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    preds = model.predict(images)\n    y_true.extend(np.argmax(labels.numpy(), axis=1))\n    y_pred.extend(np.argmax(preds, axis=1))\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# 2. Compute confusion matrix and metrics\ncm = confusion_matrix(y_true, y_pred)\naccuracy = accuracy_score(y_true, y_pred)\nmcc = matthews_corrcoef(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average='weighted')\nprecision = precision_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f'Matthews Correlation Coefficient: {mcc:.4f}')\n\n# 3. Plot confusion matrix\nplt.figure(figsize=(30, 25))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels= class_names, yticklabels= class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('efficinetnet_confusion_matrix.png', dpi=600)\nplt.savefig('efficientnet_confusion_matrix.pdf')\nplt.show()\n\n# 4. Save metrics to CSV\nmetrics = {\n    'Accuracy': [accuracy],\n    'Recall': [recall],\n    'Precision': [precision],\n    'F1 Score': [f1],\n    'MCC':[mcc]\n}\n# Save confusion matrix as CSV\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\ndf_cm.to_csv(\"confusion_matrix_efficientnet.csv\")\n\ndf_metrics_efficientnet = pd.DataFrame(metrics)\ndf_metrics_efficientnet.to_csv('performance_metrics_efficientnet.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:12:33.035775Z","iopub.execute_input":"2025-08-23T08:12:33.036055Z","iopub.status.idle":"2025-08-23T08:13:00.821061Z","shell.execute_reply.started":"2025-08-23T08:12:33.036034Z","shell.execute_reply":"2025-08-23T08:13:00.820378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><b>ConvNext</b></h1>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.convnext import ConvNeXtSmall, preprocess_input\nfrom tensorflow.keras import layers, models, optimizers\n\n# =========================\n# Parameters\n# =========================\ndata_dir = dataset_path  # your dataset folder\nimg_size = (224, 224)\nbatch_size = 32\n\n# =========================\n# Step 1: 70% Training Set\n# =========================\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.30,    # leave 30% for val+test\n    subset=\"training\",\n    seed=123,\n    image_size=img_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\n# =========================\n# Step 2: 30% Val+Test Pool\n# =========================\nval_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.30,\n    subset=\"validation\",\n    seed=123,\n    image_size=img_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\n# =========================\n# Step 3: Split Val+Test into 15% Val + 15% Test\n# =========================\nval_test_size = val_test_ds.cardinality().numpy()\nval_size = val_test_size // 2\ntest_size = val_test_size - val_size\n\nval_ds = val_test_ds.take(val_size)\ntest_ds = val_test_ds.skip(val_size)\n\n# =========================\n# Step 4: Preprocessing Function\n# =========================\nAUTOTUNE = tf.data.AUTOTUNE\n\ndef preprocess_batch(images, labels):\n    images = preprocess_input(images)  # ConvNeXt preprocessing\n    return images, labels\n\ntrain_ds = train_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\nval_ds   = val_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\ntest_ds  = test_ds.map(preprocess_batch, num_parallel_calls=AUTOTUNE)\n\n# =========================\n# Step 5: Prefetch for Performance\n# =========================\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds   = val_ds.prefetch(buffer_size=AUTOTUNE)\ntest_ds  = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n# =========================\n# Step 6: Verify Dataset Sizes\n# =========================\nnum_train = sum([images.shape[0] for images, labels in train_ds])\nnum_val   = sum([images.shape[0] for images, labels in val_ds])\nnum_test  = sum([images.shape[0] for images, labels in test_ds])\n\nprint(f\"Train images: {num_train}\")\nprint(f\"Validation images: {num_val}\")\nprint(f\"Test images: {num_test}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T17:29:04.564130Z","iopub.execute_input":"2025-08-23T17:29:04.564733Z","iopub.status.idle":"2025-08-23T17:30:14.003327Z","shell.execute_reply.started":"2025-08-23T17:29:04.564712Z","shell.execute_reply":"2025-08-23T17:30:14.002564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Model Compiling</b></h2>","metadata":{}},{"cell_type":"code","source":"# =========================\n# Model\n# =========================\nnum_classes = len(class_names)\n\nbase_model = ConvNeXtSmall(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(img_size[0], img_size[1], 3)\n)\nbase_model.trainable = False  # Freeze base model\n\n# Custom classification head\nx = base_model.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(64, activation='relu')(x)\nx = layers.Dropout(0.3)(x)\noutput = layers.Dense(num_classes, activation='softmax')(x)\n\nmodel = models.Model(inputs=base_model.input, outputs=output)\n\n# Compile\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:24:25.400735Z","iopub.execute_input":"2025-08-23T08:24:25.401004Z","iopub.status.idle":"2025-08-23T08:24:28.551782Z","shell.execute_reply.started":"2025-08-23T08:24:25.400989Z","shell.execute_reply":"2025-08-23T08:24:28.551168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:24:28.552953Z","iopub.execute_input":"2025-08-23T08:24:28.553529Z","iopub.status.idle":"2025-08-23T08:24:28.780016Z","shell.execute_reply.started":"2025-08-23T08:24:28.553510Z","shell.execute_reply":"2025-08-23T08:24:28.779324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',      # Metric to monitor\n    patience=5,              # Number of epochs with no improvement to wait\n    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n)\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\n    'best_model_convnext.h5',        # File path to save the model\n    monitor='val_loss',     # Metric to monitor\n    save_best_only=True,    # Save only when improvement\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:24:40.453491Z","iopub.execute_input":"2025-08-23T08:24:40.454080Z","iopub.status.idle":"2025-08-23T08:24:40.458668Z","shell.execute_reply.started":"2025-08-23T08:24:40.454055Z","shell.execute_reply":"2025-08-23T08:24:40.457853Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Model Training</b></h2>","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=50,\n    callbacks=[early_stopping, checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:24:43.237683Z","iopub.execute_input":"2025-08-23T08:24:43.238137Z","iopub.status.idle":"2025-08-23T08:27:31.102017Z","shell.execute_reply.started":"2025-08-23T08:24:43.238114Z","shell.execute_reply":"2025-08-23T08:27:31.101156Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Results</b></h2>","metadata":{}},{"cell_type":"code","source":"hist_training_convnext=pd.DataFrame(history.history)\nhist_training_convnext\n# Save to CSV\nhist_training_convnext.to_csv(\"hist_training_convnext.csv\", index=False)\nprint(\"ConvNext Training history to hist_training_convnext.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:27:31.103492Z","iopub.execute_input":"2025-08-23T08:27:31.103783Z","iopub.status.idle":"2025-08-23T08:27:31.109945Z","shell.execute_reply.started":"2025-08-23T08:27:31.103761Z","shell.execute_reply":"2025-08-23T08:27:31.109381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sections to modify\nfig, axs = plt.subplots(1, 2, figsize=(20, 6))\n\nnum_epochs = len(history.history['accuracy'])  # total epochs trained\n\n# X ticks positions (integers from 0 to num_epochs, step 4)\nxticks = range(0, num_epochs + 1, 4)\n\n# Plot accuracy\naxs[0].plot(history.history['accuracy'], label='Train Accuracy')\naxs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\naxs[0].set_xlabel('Epoch', fontsize=20)\naxs[0].set_ylabel('Accuracy', fontsize=20)\naxs[0].set_title('Training and Validation Accuracy - ConvNext', fontsize=22)\naxs[0].legend(fontsize=18)\naxs[0].set_xticks(xticks)\naxs[0].tick_params(axis='x', labelsize=18)\naxs[0].tick_params(axis='y', labelsize=18)\naxs[0].grid(True)\n\n# Plot loss\naxs[1].plot(history.history['loss'], label='Train Loss')\naxs[1].plot(history.history['val_loss'], label='Validation Loss')\naxs[1].set_xlabel('Epoch', fontsize=20)\naxs[1].set_ylabel('Loss', fontsize=20)\naxs[1].set_title('Training and Validation Loss - ConvNext', fontsize=22)\naxs[1].legend(fontsize=18)\naxs[1].set_xticks(xticks)\naxs[1].tick_params(axis='x', labelsize=18)\naxs[1].tick_params(axis='y', labelsize=18)\naxs[1].grid(True)\n\nplt.tight_layout()\n\n# Save the combined figure\nplt.savefig('convnext_training_curves.png', dpi=600)\nplt.savefig('convnext_training_curves.pdf')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:27:31.110692Z","iopub.execute_input":"2025-08-23T08:27:31.110955Z","iopub.status.idle":"2025-08-23T08:27:34.059787Z","shell.execute_reply.started":"2025-08-23T08:27:31.110935Z","shell.execute_reply":"2025-08-23T08:27:34.059134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n\n# 1. Get true and predicted labels\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    preds = model.predict(images)\n    y_true.extend(np.argmax(labels.numpy(), axis=1))\n    y_pred.extend(np.argmax(preds, axis=1))\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# 2. Compute confusion matrix and metrics\ncm = confusion_matrix(y_true, y_pred)\naccuracy = accuracy_score(y_true, y_pred)\nmcc = matthews_corrcoef(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average='weighted')\nprecision = precision_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f'Matthews Correlation Coefficient: {mcc:.4f}')\n\n# 3. Plot confusion matrix\nplt.figure(figsize=(30, 25))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels= class_names, yticklabels= class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('convnext_confusion_matrix.png', dpi=600)\nplt.savefig('convnext_confusion_matrix.pdf')\nplt.show()\n\n# 4. Save metrics to CSV\nmetrics = {\n    'Accuracy': [accuracy],\n    'Recall': [recall],\n    'Precision': [precision],\n    'F1 Score': [f1],\n    'MCC':[mcc]\n}\n# Save confusion matrix as CSV\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\ndf_cm.to_csv(\"confusion_matrix_convnext.csv\")\n\ndf_metrics_xception = pd.DataFrame(metrics)\ndf_metrics_xception.to_csv('performance_metrics_convnext.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:27:44.052531Z","iopub.execute_input":"2025-08-23T08:27:44.053197Z","iopub.status.idle":"2025-08-23T08:29:28.009520Z","shell.execute_reply.started":"2025-08-23T08:27:44.053173Z","shell.execute_reply":"2025-08-23T08:29:28.008712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><b>ResNet50</b></h1>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Model Compiling</b></h2>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras import layers, models, optimizers\nimport tensorflow as tf\n\n# =========================\n# Model\n# =========================\n\n# Load ResNet50 base model (pretrained on ImageNet)\nbase_model = ResNet50(\n    weights='imagenet',\n    include_top=False,                # remove default classification head\n    input_shape=(img_size[0], img_size[1], 3)\n)\nbase_model.trainable = False          # Freeze base model for transfer learning\n\n# Custom classification head\nx = base_model.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(64, activation='relu')(x)\nx = layers.Dropout(0.3)(x)\noutput = layers.Dense(num_classes, activation='softmax')(x)\n\n# Build final model\nmodel = models.Model(inputs=base_model.input, outputs=output)\n\n# Compile model\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:37:10.842793Z","iopub.execute_input":"2025-08-23T08:37:10.843305Z","iopub.status.idle":"2025-08-23T08:37:12.655711Z","shell.execute_reply.started":"2025-08-23T08:37:10.843283Z","shell.execute_reply":"2025-08-23T08:37:12.655134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:37:20.029119Z","iopub.execute_input":"2025-08-23T08:37:20.029397Z","iopub.status.idle":"2025-08-23T08:37:20.182817Z","shell.execute_reply.started":"2025-08-23T08:37:20.029366Z","shell.execute_reply":"2025-08-23T08:37:20.181988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',      # Metric to monitor\n    patience=5,              # Number of epochs with no improvement to wait\n    restore_best_weights=True  # Restore model weights from the epoch with best val_loss\n)\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\n    'best_model_resnet50.h5',        # File path to save the model\n    monitor='val_loss',     # Metric to monitor\n    save_best_only=True,    # Save only when improvement\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:38:38.807867Z","iopub.execute_input":"2025-08-23T08:38:38.808150Z","iopub.status.idle":"2025-08-23T08:38:38.812913Z","shell.execute_reply.started":"2025-08-23T08:38:38.808131Z","shell.execute_reply":"2025-08-23T08:38:38.812322Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Model Training</b></h2>","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=50,\n    callbacks=[early_stopping, checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:39:00.809302Z","iopub.execute_input":"2025-08-23T08:39:00.809608Z","iopub.status.idle":"2025-08-23T08:40:14.278962Z","shell.execute_reply.started":"2025-08-23T08:39:00.809587Z","shell.execute_reply":"2025-08-23T08:40:14.278377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Results</b></h2>","metadata":{}},{"cell_type":"code","source":"hist_training_resnet50=pd.DataFrame(history.history)\nhist_training_resnet50\n# Save to CSV\nhist_training_resnet50.to_csv(\"hist_training_resnet50.csv\", index=False)\nprint(\"ResNet50 Training history to hist_training_resnet50.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:40:54.696884Z","iopub.execute_input":"2025-08-23T08:40:54.697148Z","iopub.status.idle":"2025-08-23T08:40:54.703350Z","shell.execute_reply.started":"2025-08-23T08:40:54.697128Z","shell.execute_reply":"2025-08-23T08:40:54.702575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sections to modify\nfig, axs = plt.subplots(1, 2, figsize=(20, 6))\n\nnum_epochs = len(history.history['accuracy'])  # total epochs trained\n\n# X ticks positions (integers from 0 to num_epochs, step 4)\nxticks = range(0, num_epochs + 1, 4)\n\n# Plot accuracy\naxs[0].plot(history.history['accuracy'], label='Train Accuracy')\naxs[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\naxs[0].set_xlabel('Epoch', fontsize=20)\naxs[0].set_ylabel('Accuracy', fontsize=20)\naxs[0].set_title('Training and Validation Accuracy - ResNet50', fontsize=22)\naxs[0].legend(fontsize=18)\naxs[0].set_xticks(xticks)\naxs[0].tick_params(axis='x', labelsize=18)\naxs[0].tick_params(axis='y', labelsize=18)\naxs[0].grid(True)\n\n# Plot loss\naxs[1].plot(history.history['loss'], label='Train Loss')\naxs[1].plot(history.history['val_loss'], label='Validation Loss')\naxs[1].set_xlabel('Epoch', fontsize=20)\naxs[1].set_ylabel('Loss', fontsize=20)\naxs[1].set_title('Training and Validation Loss - ResNet50', fontsize=22)\naxs[1].legend(fontsize=18)\naxs[1].set_xticks(xticks)\naxs[1].tick_params(axis='x', labelsize=18)\naxs[1].tick_params(axis='y', labelsize=18)\naxs[1].grid(True)\n\nplt.tight_layout()\n\n# Save the combined figure\nplt.savefig('resnet50_training_curves.png', dpi=600)\nplt.savefig('resnet50_training_curves.pdf')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:41:42.967352Z","iopub.execute_input":"2025-08-23T08:41:42.967621Z","iopub.status.idle":"2025-08-23T08:41:45.891614Z","shell.execute_reply.started":"2025-08-23T08:41:42.967601Z","shell.execute_reply":"2025-08-23T08:41:45.890800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n\n# 1. Get true and predicted labels\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    preds = model.predict(images)\n    y_true.extend(np.argmax(labels.numpy(), axis=1))\n    y_pred.extend(np.argmax(preds, axis=1))\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# 2. Compute confusion matrix and metrics\ncm = confusion_matrix(y_true, y_pred)\naccuracy = accuracy_score(y_true, y_pred)\nmcc = matthews_corrcoef(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average='weighted')\nprecision = precision_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f'Matthews Correlation Coefficient: {mcc:.4f}')\n\n# 3. Plot confusion matrix\nplt.figure(figsize=(30, 25))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels= class_names, yticklabels= class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('resnet50_confusion_matrix.png', dpi=600)\nplt.savefig('resnet50_confusion_matrix.pdf')\nplt.show()\n\n# 4. Save metrics to CSV\nmetrics = {\n    'Accuracy': [accuracy],\n    'Recall': [recall],\n    'Precision': [precision],\n    'F1 Score': [f1],\n    'MCC':[mcc]\n}\n# Save confusion matrix as CSV\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\ndf_cm.to_csv(\"confusion_matrix_resnet50.csv\")\n\ndf_metrics_resnet50 = pd.DataFrame(metrics)\ndf_metrics_resnet50.to_csv('performance_metrics_resnet50.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:42:38.392851Z","iopub.execute_input":"2025-08-23T08:42:38.393139Z","iopub.status.idle":"2025-08-23T08:43:46.636157Z","shell.execute_reply.started":"2025-08-23T08:42:38.393118Z","shell.execute_reply":"2025-08-23T08:43:46.635474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><b>Zipping all outputs</b></h1>","metadata":{}},{"cell_type":"code","source":"!zip -r /kaggle/working/output_files_efficientnet_convnext_resnet50.zip /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:44:08.568500Z","iopub.execute_input":"2025-08-23T08:44:08.568781Z","iopub.status.idle":"2025-08-23T08:44:24.902246Z","shell.execute_reply.started":"2025-08-23T08:44:08.568762Z","shell.execute_reply":"2025-08-23T08:44:24.901555Z"}},"outputs":[],"execution_count":null}]}